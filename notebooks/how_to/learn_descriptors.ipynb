{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from geomfum.dataset import NotebooksDataset\n",
    "from geomfum.dfm.forward_functional_map import ForwardFunctionalMap\n",
    "from geomfum.shape import TriangleMesh\n",
    "from geomfum.descriptor.learned import LearnedDescriptor\n",
    "\n",
    "from geomfum.dfm.losses import LossManager\n",
    "from geomfum.dfm.dataset import ShapeDataset\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all possible pairs of meshes from the dataset\n",
    "def get_all_pairs(dataset):\n",
    "    shape_files = dataset.shape_files  # list of shape files in your dataset\n",
    "    # Generate all unique pairs (combinations) of shapes\n",
    "    pairs = list(itertools.combinations(shape_files, 2))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "shape_dir = '../../../datasets/shrec_r/'\n",
    "dataset = ShapeDataset(shape_dir, pair_mode='all',device='cuda')  # You can change pair_mode to 'random', 'all', or any other mode\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model and other components\n",
    "DEVICE = \"cuda\"\n",
    "loss_config = {\"Orthonormality\": 1.0}\n",
    "\n",
    "descr = LearnedDescriptor.from_registry(which='diffusion_net', cache_dir=shape_dir+'diffusion/', device=DEVICE)\n",
    "forward_map = ForwardFunctionalMap(0.0001, 1)\n",
    "\n",
    "loss_manager = LossManager(loss_config)\n",
    "optimizer = torch.optim.Adam(descr.model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    print(f\"Epoch {epoch + 1}/{100}\")\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    optimizer.zero_grad()  # Move optimizer.zero_grad() outside the batch loop for gradient accumulation\n",
    "\n",
    "    for batch_idx, (source, target) in enumerate(tqdm(train_dataloader)):\n",
    "        # Extract shape pair data\n",
    "        feat_a = descr(source)\n",
    "        feat_b = descr(target)\n",
    "\n",
    "        # Compute functional maps\n",
    "        Cxy = forward_map(source, target, feat_a, feat_b)\n",
    "\n",
    "        # Compute loss using LossManager\n",
    "        loss, loss_details = loss_manager.compute_loss(Cxy=Cxy)\n",
    "\n",
    "        # Accumulate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization step every 4 batches (adjust as needed)\n",
    "        if (batch_idx + 1) % 4 == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Log loss every 10 steps\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Processed pair {i + 1}/{len(train_dataloader)} - Loss: {loss.item():.4f}, Breakdown: {loss_details}')\n",
    "        i += 1\n",
    "\n",
    "    # Print average loss after each epoch\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{100}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save the model and pair data (optional)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        torch.save(descr.model.state_dict(), f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "\n",
    "# Testing Loop\n",
    "print(\"Testing...\")\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (source, target) in enumerate(tqdm(test_dataloader)):\n",
    "        # Extract shape pair data\n",
    "        feat_a = descr(source)\n",
    "        feat_b = descr(target)\n",
    "\n",
    "        # Compute functional maps\n",
    "        Cxy = forward_map(source, target, feat_a, feat_b)\n",
    "\n",
    "        # Compute loss using LossManager\n",
    "        loss, loss_details = loss_manager.compute_loss(Cxy=Cxy)\n",
    "\n",
    "        # Accumulate test loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f'Tested pair {batch_idx + 1}/{len(test_dataloader)} - Loss: {loss.item():.4f}, Breakdown: {loss_details}')\n",
    "\n",
    "# Print average test loss\n",
    "avg_test_loss = test_loss / len(test_dataloader)\n",
    "print(f\"Average Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
