{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbfa6b8",
   "metadata": {},
   "source": [
    "# How to learn feature for functional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade070d7",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use deep functional maps to learn feature for 3d shape matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the backend for geomstats to PyTorch, commented for github test\n",
    "import os\n",
    "\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from geomfum.convert import P2pFromFmConverter\n",
    "from geomfum.dataset.torch import PairsDataset, ShapeDataset\n",
    "from geomfum.descriptor.learned import FeatureExtractor\n",
    "from geomfum.descriptor.spectral import WaveKernelSignature\n",
    "from geomfum.forward_functional_map import ForwardFunctionalMap\n",
    "from geomfum.learning.losses import (\n",
    "    BijectivityLoss,\n",
    "    GeodesicError,\n",
    "    LaplacianCommutativityLoss,\n",
    "    LossManager,\n",
    "    OrthonormalityLoss,\n",
    ")\n",
    "from geomfum.learning.models import FMNet\n",
    "from geomfum.learning.trainer import DeepFunctionalMapTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb9bcc",
   "metadata": {},
   "source": [
    "First, we define our model. We can instantiate it combining feature extractors and forward logic, however, we provide some classic frameworks, like Functional Map network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3beadb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "fmap_module = ForwardFunctionalMap(1e3, 1, True)\n",
    "\n",
    "feature_extractor = FeatureExtractor.from_registry(\n",
    "    which=\"diffusionnet\",\n",
    "    device=\"cuda\",\n",
    "    k_eig=200,\n",
    "    in_channels=128,\n",
    "    descriptor=WaveKernelSignature(n_domain=128),\n",
    ")\n",
    "\n",
    "functional_map_model = FMNet(\n",
    "    feature_extractor=feature_extractor,\n",
    "    fmap_module=fmap_module,\n",
    "    converter=P2pFromFmConverter(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52006b",
   "metadata": {},
   "source": [
    "Then, we instantiate the training dataset. \\\n",
    "In our Datset class, we cna set boolean variable to specify what kind of objects we expect in the dataset.\\\n",
    "In the dataset folder, we always expect datas to be stored in a 'shapes' folder. \\\n",
    "If we have access to tamplate ground thruth correspondences, we can set correspondences= True, in this case we expect to have a folder called 'corr'.\n",
    "We can set spectral=True if we want to compute spectral quantities, and set distances=True if we want to compute distances, this is expensive, so we suggest to do so only for testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271d971",
   "metadata": {},
   "source": [
    "The following code download the faust dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44100ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "faust_url = \"https://raw.githubusercontent.com/JM-data/PyFuncMap/4bde4484c3e93bff925a6a82da29fa79d6862f4b/FAUST_shapes_off/\"\n",
    "shape_files = [f\"tr_reg_{i:03d}.off\" for i in range(100)]\n",
    "for fname in shape_files:\n",
    "    url = faust_url + fname\n",
    "    out_path = os.path.join(\"../../../datasets/faust/shapes/\", fname)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    urlretrieve(url, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c3187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_PATH = \"../../../datasets/faust/\"\n",
    "dataset = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=True,\n",
    "    correspondences=True,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_shapes, validation_shapes = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    validation_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f60e3b",
   "metadata": {},
   "source": [
    "Sometimes the distance computation is usefull only at validation time, so we suggest to perform the following trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5831069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "TRAIN_SET_PATH = \"../../../datasets/faust/\"\n",
    "train_shapes = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=False,\n",
    "    correspondences=False,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "val_shapes = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=True,\n",
    "    correspondences=True,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    val_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0316d",
   "metadata": {},
   "source": [
    "Then , we instantiate the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112e308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(functional_map_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d399d",
   "metadata": {},
   "source": [
    "Now we define the losses that we will consider. Again we can define our own losses, however we provide some classic functional map energies, like the orthonormality loss. \n",
    "\\\n",
    "For evaluation, we can use training losses, or we can compute the geodesic distance loss, to evaluate the estimates.\\\n",
    "We note that this loss makes sense only if we ahve access to a ground thruth correspondence or if the shapes share the same triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04caeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "losses = [\n",
    "    OrthonormalityLoss(weight=1.0),\n",
    "    BijectivityLoss(weight=1.0),\n",
    "    LaplacianCommutativityLoss(weight=1e-3),\n",
    "]\n",
    "loss_manager = LossManager(losses)\n",
    "\n",
    "losses = [\n",
    "    GeodesicError(),\n",
    "]\n",
    "\n",
    "val_loss_manager = LossManager(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24792a",
   "metadata": {},
   "source": [
    "We have defined a trainer for simplicity that thakes as input model, losses, train and val datasets and optimizer and manages the training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a717fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepFunctionalMapTrainer(\n",
    "    model=functional_map_model,\n",
    "    train_loss_manager=loss_manager,\n",
    "    val_loss_manager=val_loss_manager,\n",
    "    train_set=train_dataset,\n",
    "    val_set=validation_dataset,\n",
    "    optimizer=optimizer,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch [1/10] - Training\n",
      "Epoch 1/10 (Train):   0%|          | 0/6320 [00:00<?, ?batch/s]/home/ubuntu/giulio_vigano/geomfum_proj/geomfum/geomfum/wrap/diffusionnet.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_feat = torch.tensor(input_feat).to(torch.float32).to(self.device)\n",
      "Epoch 1/10 (Train):   0%|          | 3/6320 [01:13<42:46:10, 24.37s/batch, Loss=301.4008]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "requires": [
   "skip"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
