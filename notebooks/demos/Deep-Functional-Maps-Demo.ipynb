{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbfa6b8",
   "metadata": {},
   "source": [
    "# How to learn feature for functional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade070d7",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use deep functional maps to learn feature for 3d shape matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b18e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the backend for geomstats to PyTorch, commented for github test\n",
    "import os\n",
    "\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from geomfum.convert import P2pFromFmConverter\n",
    "from geomfum.dataset.torch import PairsDataset, ShapeDataset\n",
    "from geomfum.descriptor.learned import FeatureExtractor\n",
    "from geomfum.forward_functional_map import ForwardFunctionalMap\n",
    "from geomfum.learning.losses import (\n",
    "    BijectivityLoss,\n",
    "    GeodesicError,\n",
    "    LaplacianCommutativityLoss,\n",
    "    LossManager,\n",
    "    OrthonormalityLoss,\n",
    ")\n",
    "from geomfum.learning.models import FMNet\n",
    "from geomfum.learning.trainer import DeepFunctionalMapTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb9bcc",
   "metadata": {},
   "source": [
    "First, we define our model. We can instantiate it combining feature extractors and forward logic, however, we provide some classic frameworks, like Functional Map network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3beadb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "fmap_module = ForwardFunctionalMap(1e3, 1, True)\n",
    "\n",
    "feature_extractor = FeatureExtractor.from_registry(\n",
    "    which=\"diffusionnet\",\n",
    "    device=\"cuda\",\n",
    "    k_eig=200,\n",
    ")\n",
    "\n",
    "functional_map_model = FMNet(\n",
    "    feature_extractor=feature_extractor,\n",
    "    fmap_module=fmap_module,\n",
    "    converter=P2pFromFmConverter(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52006b",
   "metadata": {},
   "source": [
    "Then, we instantiate the training dataset. \\\n",
    "In our Datset class, we cna set boolean variable to specify what kind of objects we expect in the dataset.\\\n",
    "In the dataset folder, we always expect datas to be stored in a 'shapes' folder. \\\n",
    "If we have access to tamplate ground thruth correspondences, we can set correspondences= True, in this case we expect to have a folder called 'corr'.\n",
    "We can set spectral=True if we want to compute spectral quantities, and set distances=True if we want to compute distances, this is expensive, so we suggest to do so only for testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c3187c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m TRAIN_SET_PATH = \u001b[33m\"\u001b[39m\u001b[33m../../../datasets/smal/train_set/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mShapeDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTRAIN_SET_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectral\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m train_size = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.8\u001b[39m * \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[32m      6\u001b[39m val_size = \u001b[38;5;28mlen\u001b[39m(dataset) - train_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/dataset/torch.py:74\u001b[39m, in \u001b[36mShapeDataset.__init__\u001b[39m\u001b[34m(self, dataset_dir, spectral, distances, correspondences, k, device)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m meshio._helpers._writer_map:\n\u001b[32m     73\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipped unsupported mesh file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     75\u001b[39m filepath = os.path.join(\u001b[38;5;28mself\u001b[39m.shape_dir, filename)\n\u001b[32m     76\u001b[39m mesh = TriangleMesh.from_file(filepath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/operator.py:193\u001b[39m, in \u001b[36mLaplacian.find_spectrum\u001b[39m\u001b[34m(self, spectrum_size, laplacian_spectrum_finder, set_as_basis, recompute)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m laplacian_spectrum_finder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    187\u001b[39m     laplacian_spectrum_finder = LaplacianSpectrumFinder(\n\u001b[32m    188\u001b[39m         spectrum_size=spectrum_size,\n\u001b[32m    189\u001b[39m         nonzero=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    190\u001b[39m         fix_sign=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    191\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28mself\u001b[39m._basis = \u001b[43mlaplacian_spectrum_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_basis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m set_as_basis:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m._shape.set_basis(\u001b[38;5;28mself\u001b[39m.basis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/laplacian.py:175\u001b[39m, in \u001b[36mLaplacianSpectrumFinder.__call__\u001b[39m\u001b[34m(self, shape, as_basis, recompute)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Apply algorithm.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m \u001b[33;03m    A basis. (If ``basis is True``.)\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    171\u001b[39m stiffness_matrix, mass_matrix = shape.laplacian.find(\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.laplacian_finder, recompute=recompute\n\u001b[32m    173\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m eigenvals, eigenvecs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meig_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstiffness_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmass_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nonzero:\n\u001b[32m    178\u001b[39m     eigenvals = eigenvals[\u001b[32m1\u001b[39m:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/numerics/eig.py:19\u001b[39m, in \u001b[36mScipyEigsh.__call__\u001b[39m\u001b[34m(self, A, M)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, A, M=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     vals, vecs = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_scipy_csc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspectrum_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_scipy_dia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gs.from_numpy(vals), gs.from_numpy(vecs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1698\u001b[39m, in \u001b[36meigsh\u001b[39m\u001b[34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[39m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params.converged:\n\u001b[32m-> \u001b[39m\u001b[32m1698\u001b[39m         \u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1700\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m params.extract(return_eigenvectors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/venv/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:544\u001b[39m, in \u001b[36m_SymmetricArpackParams.iterate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    543\u001b[39m     \u001b[38;5;28mself\u001b[39m.ido, \u001b[38;5;28mself\u001b[39m.tol, \u001b[38;5;28mself\u001b[39m.resid, \u001b[38;5;28mself\u001b[39m.v, \u001b[38;5;28mself\u001b[39m.iparam, \u001b[38;5;28mself\u001b[39m.ipntr, \u001b[38;5;28mself\u001b[39m.info = \\\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arpack_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mido\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mipntr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    548\u001b[39m     xslice = \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m.ipntr[\u001b[32m0\u001b[39m] - \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.ipntr[\u001b[32m0\u001b[39m] - \u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.n)\n\u001b[32m    549\u001b[39m     yslice = \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m.ipntr[\u001b[32m1\u001b[39m] - \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.ipntr[\u001b[32m1\u001b[39m] - \u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.n)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "TRAIN_SET_PATH = \"../../../datasets/smal/train_set/\"\n",
    "dataset = ShapeDataset(\n",
    "    TRAIN_SET_PATH, spectral=True, distances=False, device=\"cuda\", k=30\n",
    ")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_shapes, validation_shapes = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    validation_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f60e3b",
   "metadata": {},
   "source": [
    "Sometimes the distance computation is usefull only at validation time, so we suggest to perform the following trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5831069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "TRAIN_SET_PATH = \"../../../datasets/smal/test_set/\"\n",
    "dataset1 = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=False,\n",
    "    correspondences=False,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "dataset2 = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=True,\n",
    "    correspondences=True,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset1))\n",
    "val_size = len(dataset1) - train_size\n",
    "\n",
    "train_shapes, validation_shapes = random_split(dataset1, [train_size, val_size])\n",
    "# Create the full list of indices and shuffle\n",
    "train_indices = train_shapes.indices\n",
    "val_indices = validation_shapes.indices\n",
    "\n",
    "train_shapes = Subset(dataset1, train_indices)\n",
    "validation_shapes = Subset(dataset2, val_indices)\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    validation_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0316d",
   "metadata": {},
   "source": [
    "Then , we instantiate the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "112e308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(functional_map_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d399d",
   "metadata": {},
   "source": [
    "Now we define the losses that we will consider. Again we can define our own losses, however we provide some classic functional map energies, like the orthonormality loss. \n",
    "\\\n",
    "For evaluation, we can use training losses, or we can compute the geodesic distance loss, to evaluate the estimates.\\\n",
    "We note that this loss makes sense only if we ahve access to a ground thruth correspondence or if the shapes share the same triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04caeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "losses = [\n",
    "    OrthonormalityLoss(weight=1.0),\n",
    "    BijectivityLoss(weight=1.0),\n",
    "    LaplacianCommutativityLoss(weight=1e-3),\n",
    "]\n",
    "loss_manager = LossManager(losses)\n",
    "\n",
    "losses = [\n",
    "    GeodesicError(),\n",
    "]\n",
    "\n",
    "val_loss_manager = LossManager(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24792a",
   "metadata": {},
   "source": [
    "We have defined a trainer for simplicity that thakes as input model, losses, train and val datasets and optimizer and manages the training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a717fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepFunctionalMapTrainer(\n",
    "    model=functional_map_model,\n",
    "    train_loss_manager=loss_manager,\n",
    "    val_loss_manager=val_loss_manager,\n",
    "    train_set=train_dataset,\n",
    "    val_set=validation_dataset,\n",
    "    optimizer=optimizer,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6458c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch [1/10] - Training\n",
      "Epoch 1/10 (Train):   0%|          | 0/240 [00:03<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/learning/trainer.py:181\u001b[39m, in \u001b[36mDeepFunctionalMapTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.epochs):\n\u001b[32m    180\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] - Training\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     avg_train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     logging.info(\n\u001b[32m    183\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] - Average Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m     )\n\u001b[32m    186\u001b[39m     avg_val_loss, val_metrics = \u001b[38;5;28mself\u001b[39m.validate(return_metrics=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/geomfum/geomfum/learning/trainer.py:125\u001b[39m, in \u001b[36mDeepFunctionalMapTrainer.train_one_epoch\u001b[39m\u001b[34m(self, epoch)\u001b[39m\n\u001b[32m    116\u001b[39m     outputs.update(\n\u001b[32m    117\u001b[39m         {\n\u001b[32m    118\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdist_a\u001b[39m\u001b[33m\"\u001b[39m: pair[\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdist_matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    119\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdist_b\u001b[39m\u001b[33m\"\u001b[39m: pair[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdist_matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    120\u001b[39m         }\n\u001b[32m    121\u001b[39m     )\n\u001b[32m    123\u001b[39m loss, loss_dict = \u001b[38;5;28mself\u001b[39m.train_loss_manager.compute_loss(outputs)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m    127\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/giulio_vigano/geomfum_proj/venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = train_dataset[0]\n",
    "mesh1 = data1[\"source\"][\"mesh\"]\n",
    "mesh2 = data1[\"target\"][\"mesh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe010e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e82d9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainer.model.feature_extractor(mesh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ffbc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geomstats.backend as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07de0e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3249, -0.2951, -0.4287,  ..., -0.3962, -0.3062, -0.4485],\n",
       "        [-0.3282, -0.4835, -0.3857,  ..., -0.3310, -0.4567, -0.3650],\n",
       "        [-0.0126, -0.0301,  0.0446,  ...,  0.0626, -0.0043,  0.0265],\n",
       "        ...,\n",
       "        [-0.1333, -0.1450, -0.1222,  ..., -0.1283, -0.0805, -0.1357],\n",
       "        [-0.1456, -0.1540, -0.2034,  ..., -0.3405, -0.2318, -0.2368],\n",
       "        [ 0.0217, -0.0133,  0.0037,  ..., -0.0888, -0.0129, -0.0303]],\n",
       "       device='cuda:0', grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.array(a.squeeze().double().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "requires": [
   "skip"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
