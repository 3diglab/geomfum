{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbfa6b8",
   "metadata": {},
   "source": [
    "# How to learn feature for functional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade070d7",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use deep functional maps to learn feature for 3d shape matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b18e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the backend for geomstats to PyTorch, commented for github test\n",
    "import os\n",
    "\n",
    "os.environ[\"GEOMSTATS_BACKEND\"] = \"pytorch\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from geomfum.convert import P2pFromFmConverter\n",
    "from geomfum.dataset.torch import PairsDataset, ShapeDataset\n",
    "from geomfum.descriptor.learned import FeatureExtractor\n",
    "from geomfum.descriptor.spectral import WaveKernelSignature\n",
    "from geomfum.forward_functional_map import ForwardFunctionalMap\n",
    "from geomfum.learning.losses import (\n",
    "    BijectivityLoss,\n",
    "    GeodesicError,\n",
    "    LaplacianCommutativityLoss,\n",
    "    LossManager,\n",
    "    OrthonormalityLoss,\n",
    ")\n",
    "from geomfum.learning.models import FMNet\n",
    "from geomfum.learning.trainer import DeepFunctionalMapTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb9bcc",
   "metadata": {},
   "source": [
    "First, we define our model. We can instantiate it combining feature extractors and forward logic, however, we provide some classic frameworks, like Functional Map network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3beadb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "fmap_module = ForwardFunctionalMap(1e3, 1, True)\n",
    "\n",
    "feature_extractor = FeatureExtractor.from_registry(\n",
    "    which=\"diffusionnet\",\n",
    "    device=\"cuda\",\n",
    "    k_eig=200,\n",
    "    in_channels=128,\n",
    "    descriptor=WaveKernelSignature(n_domain=128),\n",
    ")\n",
    "\n",
    "functional_map_model = FMNet(\n",
    "    feature_extractor=feature_extractor,\n",
    "    fmap_module=fmap_module,\n",
    "    converter=P2pFromFmConverter(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52006b",
   "metadata": {},
   "source": [
    "Then, we instantiate the training dataset. \\\n",
    "In our Datset class, we cna set boolean variable to specify what kind of objects we expect in the dataset.\\\n",
    "In the dataset folder, we always expect datas to be stored in a 'shapes' folder. \\\n",
    "If we have access to tamplate ground thruth correspondences, we can set correspondences= True, in this case we expect to have a folder called 'corr'.\n",
    "We can set spectral=True if we want to compute spectral quantities, and set distances=True if we want to compute distances, this is expensive, so we suggest to do so only for testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\OneDrive\\Research\\geomfum_proj\\geomfum\\geomfum\\_backend\\pytorch\\sparse.py:22: UserWarning: Sparse CSC tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return _torch.sparse_csc_tensor(ccol_indices, row_indices, values, size=array.shape)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SET_PATH = \"../../../datasets/faust/test_set/\"\n",
    "dataset = ShapeDataset(\n",
    "    TRAIN_SET_PATH, spectral=True, distances=False, device=\"cuda\", k=30\n",
    ")\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_shapes, validation_shapes = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    validation_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f60e3b",
   "metadata": {},
   "source": [
    "Sometimes the distance computation is usefull only at validation time, so we suggest to perform the following trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5831069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "TRAIN_SET_PATH = \"../../../datasets/faust/test_set/\"\n",
    "dataset1 = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=False,\n",
    "    correspondences=False,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "dataset2 = ShapeDataset(\n",
    "    TRAIN_SET_PATH,\n",
    "    spectral=True,\n",
    "    distances=True,\n",
    "    correspondences=True,\n",
    "    device=\"cuda\",\n",
    "    k=30,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset1))\n",
    "val_size = len(dataset1) - train_size\n",
    "\n",
    "train_shapes, validation_shapes = random_split(dataset1, [train_size, val_size])\n",
    "# Create the full list of indices and shuffle\n",
    "train_indices = train_shapes.indices\n",
    "val_indices = validation_shapes.indices\n",
    "\n",
    "train_shapes = Subset(dataset1, train_indices)\n",
    "validation_shapes = Subset(dataset2, val_indices)\n",
    "\n",
    "train_dataset = PairsDataset(\n",
    "    train_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n",
    "\n",
    "validation_dataset = PairsDataset(\n",
    "    validation_shapes,\n",
    "    pair_mode=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0316d",
   "metadata": {},
   "source": [
    "Then , we instantiate the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "112e308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(functional_map_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d399d",
   "metadata": {},
   "source": [
    "Now we define the losses that we will consider. Again we can define our own losses, however we provide some classic functional map energies, like the orthonormality loss. \n",
    "\\\n",
    "For evaluation, we can use training losses, or we can compute the geodesic distance loss, to evaluate the estimates.\\\n",
    "We note that this loss makes sense only if we ahve access to a ground thruth correspondence or if the shapes share the same triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04caeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "losses = [\n",
    "    OrthonormalityLoss(weight=1.0),\n",
    "    BijectivityLoss(weight=1.0),\n",
    "    LaplacianCommutativityLoss(weight=1e-3),\n",
    "]\n",
    "loss_manager = LossManager(losses)\n",
    "\n",
    "losses = [\n",
    "    GeodesicError(),\n",
    "]\n",
    "\n",
    "val_loss_manager = LossManager(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24792a",
   "metadata": {},
   "source": [
    "We have defined a trainer for simplicity that thakes as input model, losses, train and val datasets and optimizer and manages the training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a717fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DeepFunctionalMapTrainer(\n",
    "    model=functional_map_model,\n",
    "    train_loss_manager=loss_manager,\n",
    "    val_loss_manager=val_loss_manager,\n",
    "    train_set=train_dataset,\n",
    "    val_set=validation_dataset,\n",
    "    optimizer=optimizer,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6458c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch [1/10] - Training\n",
      "Epoch 1/10 (Train):   0%|          | 0/240 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tr_reg_094.off'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Research\\geomfum_proj\\geomfum\\geomfum\\learning\\trainer.py:181\u001b[0m, in \u001b[0;36mDeepFunctionalMapTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m    180\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - Average Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    186\u001b[0m     avg_val_loss, val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(return_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\Research\\geomfum_proj\\geomfum\\geomfum\\learning\\trainer.py:97\u001b[0m, in \u001b[0;36mDeepFunctionalMapTrainer.train_one_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[0;32m     92\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set),\n\u001b[0;32m     93\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     95\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[1;32m---> 97\u001b[0m         pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Access item by index\u001b[39;00m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     99\u001b[0m         mesh_a \u001b[38;5;241m=\u001b[39m pair[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\OneDrive\\Research\\geomfum_proj\\geomfum\\geomfum\\dataset\\torch.py:230\u001b[0m, in \u001b[0;36mPairsDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get item by index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    Dictionary containing the source and target shapes.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m src_idx, tgt_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairs[idx]\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msrc_idx\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_data[tgt_idx]}\n",
      "File \u001b[1;32mc:\\USERS\\GIULI\\ONEDRIVE\\RESEARCH\\GEOMFUM_PROJ\\VENV\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Research\\geomfum_proj\\geomfum\\geomfum\\dataset\\torch.py:121\u001b[0m, in \u001b[0;36mShapeDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    118\u001b[0m shape_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrespondences:\n\u001b[1;32m--> 121\u001b[0m     shape_data\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorr\u001b[39m\u001b[38;5;124m\"\u001b[39m: gs\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m)})\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistances:\n\u001b[0;32m    124\u001b[0m     mat_subfolder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tr_reg_094.off'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = train_dataset[0]\n",
    "mesh1 = data1[\"source\"][\"mesh\"]\n",
    "mesh2 = data1[\"target\"][\"mesh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe010e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainer.model.feature_extractor(mesh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geomstats.backend as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de0e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3249, -0.2951, -0.4287,  ..., -0.3962, -0.3062, -0.4485],\n",
       "        [-0.3282, -0.4835, -0.3857,  ..., -0.3310, -0.4567, -0.3650],\n",
       "        [-0.0126, -0.0301,  0.0446,  ...,  0.0626, -0.0043,  0.0265],\n",
       "        ...,\n",
       "        [-0.1333, -0.1450, -0.1222,  ..., -0.1283, -0.0805, -0.1357],\n",
       "        [-0.1456, -0.1540, -0.2034,  ..., -0.3405, -0.2318, -0.2368],\n",
       "        [ 0.0217, -0.0133,  0.0037,  ..., -0.0888, -0.0129, -0.0303]],\n",
       "       device='cuda:0', grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.array(a.squeeze().double().T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "requires": [
   "skip"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
